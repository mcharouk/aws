# EC2

* Multi volume snapshots can snapshot all or part of an EC2 instance. So Resource Type must be Instance when starting a snapshot from the console
* to enable detailed monitoring

```
aws ec2 monitor-instances --instance-ids [instances-comma-separated-list]
```


## EC2 instance connect

* Necessary steps
  * Configure IAM roles to be able to connect with Instance Connect
  * Open Inbound SSH on SG
  * EC2 instance connect must be installed on instance (manual install or use an AMI where it is already installed)
  * Optionnally install EC2 Instance Connect CLI locally if connection is not browser based

## Reserved Instances

* Capacity reservation (Reserved Instances) can be shared accross all accounts whether on the same organization or not.
* Capacity reservation is only supported for Zonal instances, not regional instances
* It's possible to queue purchase of reserved instances, to be sure reserved instances will be covered without any interruption.
* Can be queued only on Regional Reserved Instances (not Zonal) and not for Reserved Instances from other sellers than AWS. 


## Dedicated host recovery

* Dedicated host recovery is a feature that automically recover dedicated host in case of issues like
  * Loss of network connectivity
  * Loss of system power
  * Hardware or software issues on the physical host
* The old Dedicated host will not be released if some instances like using instance-store are running on the physical host. Manual recovery must be made in this case (manual copy of the data for example).

# SQS

* To change Visibility Timeout

```
aws sqs change-message-visibility --queue-url myQueue --receipt-handle MyReceipt --visibility-timeout 30
```

* user SQS Extended Client Library to manage payload on S3 (if payload exceeds 256 Ko). Available in Python or Java
* DLQ and Standard queue must reside in same region and account and must be of the same type (Standard or FIFO)
* Create Delay queues to delay the delivery of message to consumer. It's a queue with the Delivery Delay set to something > 0


# ECR

* to retag docker images, use put-image and --image-tag option
* enhanced scanning to use inspector and activate continuous scanning. Must specify filter, without it, no images will be scanned
* use docker manifest push instead of docker push to push multi architecture images

# CodeDeploy

* Lifecycle
  * ApplicationStop
  * BeforeInstall
  * AfterInstall
  * ApplicationStart
  * ValidateService
* If deployment log file has been deleted, codeDeploy service must be restarted to create a new one

# Code Build

* Phases
  * Install
  * Pre_build
  * Build
  * Post_build

* For each phase, we give parameters
  * run-as (linux user name)
  * on-failure (ABORT or CONTINUE)
  * commands (all commands to run)
  * finally (run even if a command fails)

* custom images can be pulled from ECR, Docker hub or any private registry
* CodeBuild doesn't cache the image

# XRay

* -o option to run daemon locally (not on EC2 instance)

```
~/xray-daemon$ ./xray -o
```
* X ray can work cross-regions
* Enable **Active Tracing** when there is no upstream service that has x-ray activated
* Trace header is excluded from SQS message size. It's not part of a message content, but is part of a default http header
* Lambda environment variables
  * _X_AMZN_TRACE_ID : Contains Tracing Header
  * AWS_XRAY_CONTEXT_MISSING : determine behavior when trying to log data to x ray but tracing header is not available
  * AWS_XRAY_DAEMON_ADDRESS : address of x ray daemon to send directly to xray without using SDK
* Default Sampling rule : One request per second & 10 % of any additional request / host
* there are [filters](https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html) that can be used in the console to filter X Ray traces
  * **Service** keyword takes all traces generated by a specific service
  * **edge(ServiceA, ServiceB)** select all traces between A and B
  * **annotation\[key\]** filters by annotation
  * **group.name** or **group.arn**

# Beanstalk

* for custom platform, needs to specify AMI and associated region
* cron.yaml file must be provided if a worker must also run periodic tasks
* Beanstalk creates a new version of application each time a new code is uploaded. Packages are stored on S3 and must be explicity deleted if needed
* Configurations (in .ebextensions) and code must be provided in a single zip file

# DynamoDB

* for TTL, any field name can be chosen for the expiry timestamp 
* can use DynamoDBCrudPolicy policy to give access
* On a Query, it's possible to return Consumed Capacity. 3 values can be provided
  * NONE (default)
  * TOTAL (amount of RCU)
  * INDEXES (amount of RCU for each table and index that was accessed)

# Kinesis 

* IteratorAge (now deprected in favour of **IteratorAgeMilliseconds**). Time difference between now and last GetRecord call to the stream. This can indicates that consumer is lagging to process all messages 

# Lambda

* MobileSDK can be used to get easy information on devices using Context object.
* Weighted alias : percentage is a number between 0 and 1
* When processing an SQS queue, property ReportBatchItemFailures helps re-processing only items that have failed when processing a batch of items
* When publishing a new version, must specify the current version id. This is to prevent multiple developers publishing versions at the same time that results into conflicts.
* multi-architecture container images are not supported for Lambda with Docker

# Exceptions

Status Code 429 is for Too Many Requests. Raised when some services are throttling.

# S3

* Object Lock is tied to a specific version of an object
* Expedited Retrieval is not possible from Glacier Deep Archive.
* PrincipalOrgPaths condition in Principal to control access to a specific OU

# Fault Injection Simulator

Template : 
  * Action Set
  * Targets
    * Can specify AWS Resources with Ids, Tags or Resource Filters
  * Stop Conditions

# Certificate Manager

* [Certificate Revocation](./devops.md#certificate-revocation)


# SNS

* Delivery Policy can be set at topic or subscription level
* Delivery Policy aims to deliver failed messages to a DLQ (SQS)
* DLQ and subscriptions must be created in the same region

# SAM

* to deploy locally in integration tests, run

```
sam local start-lambda
```

* to deploy localy and test manually, run 

```
sam local invoke
```

# KMS

* LocalCryptoMaterialsCache is provided by AWS SDK and help caching data keys for reuse.

# Parameter Store

* to get a secret string decrypted or unencrypted use flag

```
--with-decryption | --no-with-decryption
```

* parameter store params can be shared accross accounts (from Feb 2024)

# ELB

Cross-Zone Load Balancing is always enabled by default for **ALB**

# Billing And Cost Management

* IAM User access must be explicitly activated in Billing and Cost Mgt to allow Users to see the data
* AWS requires approximately **5** weeks of usage data to generate budget **forecasts**

# ASG

* Target Tracking Policy does not support directly scaling based on ApproximateNumberOfMessages. But it's possible to calculate a custom metric taking account of ApproximateNumberOfMessages, Number of instances in ASG, and acceptable backlog size per instance to use target tracking. More details [here](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html)